\newpage \section*{Exercice 3}

\noindent \textbf{1. a) Préciser l’espace des individus et l’espace des variables.}

\noindent Il y a quatre individu donc l'espace des individus est $\mathbb{R}^4$

\noindent Il y a trois variables, donc l'espace des variables est $\mathbb{R}^3$\\

\noindent \textbf{1. b) Calculer la matrice R des corrélations. }

Afin de calculer la matrice de corrélation, nous allons d'abord centrer-réduire les différentes valeurs grâce à la formule : $x^j = \frac{\displaystyle X^j-\overline{X}^j}{\displaystyle \sigma_{X^j}}$

Pour cela, il faudra l'écart-type et la moyenne de chaque colonne du tableau grâce aux formules respectives : $\sigma_{X^j}=\sqrt{\frac{\displaystyle 1}{\displaystyle n-1} \displaystyle  \sum_{i=1}^{n} \displaystyle \left(X^j - \overline{X}^j\right)^2}$ et $\overline{X}^j = \frac{\displaystyle 1}{\displaystyle n} \displaystyle \sum_{i=1}^{n} X^j$ 


Dès lors, nous pouvons calculer la matrice de corrélation $\text{R}=\frac{\displaystyle 1}{\displaystyle  n}x'x$


% Table generated by Excel2LaTeX from sheet 'EX3'
\begin{table}[htbp]
	\centering
	\begin{tabular}{c|c|c|c}
		\hline
		Mean   & 1,00   & 3,00   & -2,00 \\ \hline
		std-Error & 2,31   & 1,15   & 1,15 \\ \hline
	\end{tabular}%
	\caption{Moyennes et écart-type de chaque colonne}
\end{table}%

% Table generated by Excel2LaTeX from sheet 'EX3'
\begin{table}[htbp]
	\centering
	
	\begin{tabular}{c|c|c}
		\hline
		-0,87  & 0,87   & 0,87 \\ \hline
		-0,87  & -0,87  & 0,87 \\ \hline
		0,87   & 0,87   & -0,87 \\ \hline
		0,87   & -0,87  & -0,87 \\ \hline
	\end{tabular}%
	\caption{{Valeurs centrées réduites}}
\end{table}%

% Table generated by Excel2LaTeX from sheet 'EX3'
\begin{table}[htbp]
	\centering
	\begin{tabular}{c|c|c}
		\hline
		1,00   & 0,00   & -1,00 \\ \hline
		0,00   & 1,00   & 0,00 \\ \hline
		-1,00  & 0,00   & 1,00 \\ \hline
	\end{tabular}%
	\caption{Matrice de corrélation}
\end{table}%




\noindent \textbf{2. Donner l’analogie d’une part, et la différence d’autre part, entre une variable discriminante et une composante principale.}


\noindent \underline{Objectif :}

\begin{itemize}
	\item Les variables discriminantes sont utilisées dans l'analyse discriminante pour trouver des combinaisons linéaires de variables qui maximisent la séparation entre les groupes de données connus.
	\item Les composantes principales sont utilisées dans l'analyse en composantes principales pour réduire la dimensionnalité des données en trouvant des directions qui capturent le plus de variance possible.
\end{itemize}

\noindent \underline{Nature :}

\begin{itemize}
	\item Les variables discriminantes sont spécifiques à un problème de classification particulier. Elles sont sélectionnées pour leur capacité à séparer les groupes de données.
	\item Les composantes principales sont des axes de variation dans l'ensemble de données d'origine. Elles ne sont pas spécifiques à un problème de classification particulier, mais visent plutôt à réduire la complexité des données.
\end{itemize}

\noindent \underline{Interprétation :}

\begin{itemize}
	\item Les variables discriminantes sont souvent interprétées en termes de contribution à la séparation entre les groupes de données.
	\item Les composantes principales sont interprétées en termes de contribution à la variance totale des données.
\end{itemize}

\noindent \textbf{3) Démontrer que la diagonale principale d’une matrice des corrélations est un vecteur 
	unitaire.}

Sachant que lorsqu'on fait la moyenne du produit de la la matrice centrée-réduite et de sa transposée, on obtient donc la matrice de corrélation R dont la diagonale est égale à : $\displaystyle \frac{\displaystyle 1}{\displaystyle n}\sum_{i=1}^{n} \left(\displaystyle \frac{\displaystyle X^j-\overline{X}^j}{\displaystyle \sigma_{X}^j}\right)^2$ Par ailleurs, sachant que $x^j=\displaystyle \frac{\displaystyle X^j - \overline{X}}{\displaystyle \sigma_{X}^2} \Rightarrow x\rightsquigarrow \mathcal{N}(0,1)$ Or sachant que sur la diagonale nous avons : $d_j=\frac{\displaystyle 1}{\displaystyle n}\displaystyle \sum_{i=1}^{n} \left(x^j\right)^2$ et comme $x^j \rightsquigarrow \mathcal{N}(0,1)$ alors $\left(x^j\right)^2 \rightsquigarrow \chi^2(1)$ Ainsi, $$d_j = \frac{\displaystyle 1}{\displaystyle n}\displaystyle \sum_{i=1}^{n} \chi^2(1)=\frac{\displaystyle 1}{\displaystyle n}\chi^2(n)=\frac{\displaystyle 1}{\displaystyle n} \times n=1$$
C'est pourquoi la diagonale de la matrice de corrélation est égale au vecteur unitaire.\\

\noindent \textbf{4) Quelle est l’utilité du test d’indépendance du Chi-deux $(\chi^2)$ dans la mise en œuvre de l’analyse factorielle des correspondances ? }

Le test d'indépendance du $\chi^2$ permet de vérifier la dépendance entre les deux variables. Il est donc déterminant dans le processus de décision d'effectuer une (AFC) ou non.